{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laL6ia-Tojeg",
        "outputId": "ae5954b3-db14-43df-d3b1-1b022316a985"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJmFdlvYnMF8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2027YB6PnMF9"
      },
      "outputs": [],
      "source": [
        "data1=pd.read_csv('/content/drive/MyDrive/backpack_train.csv')\n",
        "data2=pd.read_csv('/content/drive/MyDrive/backback_train_extra.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plHtFpRunMF-"
      },
      "outputs": [],
      "source": [
        "data=pd.concat([data1,data2],ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT4BSQ6NnMF_",
        "outputId": "2c5b6bb3-977b-4120-9a60-410f9dc52c05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3994318, 11)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYDBlFLnnMGA"
      },
      "outputs": [],
      "source": [
        "data=data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WZkVukEnMGB",
        "outputId": "f726b405-e1b9-4b1a-8256-04d163fc42f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3288503, 11)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDvh0vCQnMGC",
        "outputId": "8b634cd2-09eb-44a3-d078-be40c115e7ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof',\n",
            "       'Style', 'Color'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "cat_cols=data.select_dtypes(include='object').columns\n",
        "print(cat_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZg2rTAlnMGD"
      },
      "outputs": [],
      "source": [
        "label_encoders = {}\n",
        "categorical_cols = ['Brand', 'Material', 'Style','Color']\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    # predict_data[col]=le.transform(predict_data[col])\n",
        "    label_encoders[col] = le  # Store for inverse transformation if needed\n",
        "\n",
        "# Binary Encoding for Yes/No features\n",
        "data['Laptop Compartment'] = data['Laptop Compartment'].map({'Yes': 1, 'No': 0})\n",
        "# predict_data['Laptop Compartment'] = predict_data['Laptop Compartment'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "data['Waterproof'] = data['Waterproof'].map({'Yes': 1, 'No': 0})\n",
        "# predict_data['Waterproof'] = predict_data['Waterproof'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "data['Size']=data['Size'].map({'Small':0,'Medium':1,'Large':2})\n",
        "# predict_data['Size']=predict_data['Size'].map({'Small':0,'Medium':1,'Large':2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWTkU6UGnMGE",
        "outputId": "2f804e41-7f2b-4675-d259-c6672ebf5cec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Brand': LabelEncoder(),\n",
              " 'Material': LabelEncoder(),\n",
              " 'Style': LabelEncoder(),\n",
              " 'Color': LabelEncoder()}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFiYpFKOnMGF"
      },
      "outputs": [],
      "source": [
        "data.drop('id', axis=1, inplace=True)\n",
        "# predict_data.drop('id', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOSw_DoUnMGF"
      },
      "outputs": [],
      "source": [
        "# Assign last column to y\n",
        "y = data.iloc[:, -1]\n",
        "# Assign remaining columns to X\n",
        "x = data.iloc[:, :-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpsUALnznMGG",
        "outputId": "d75ff52e-5c11-4995-b72e-f5356200bad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Weight Capacity (kg)'] 9\n"
          ]
        }
      ],
      "source": [
        "numerical_cols = [x for x in x.columns]\n",
        "print(numerical_cols,len(numerical_cols))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi1fvfGDnMGH",
        "outputId": "202c5616-f06c-4c28-8d90-cf6b0e3a419d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brand : [1 4 2 0 3]\n",
            "Material : [1 0 2 3]\n",
            "Size : [1 0 2]\n",
            "Compartments : [ 7. 10.  2.  8.  1.  5.  3.  6.  4.  9.]\n",
            "Laptop Compartment : [1 0]\n",
            "Waterproof : [0 1]\n",
            "Style : [2 1 0]\n",
            "Color : [0 3 5 1 2 4]\n",
            "Weight Capacity (kg) : [11.61172281 27.07853658 16.64375995 ...  9.54895871 12.79080004\n",
            " 16.64173875]\n"
          ]
        }
      ],
      "source": [
        "for i in x.columns:\n",
        "  print(f\"{i} : {x[i].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9C7g0FDnMGH"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "x[numerical_cols] = scaler.fit_transform(x[numerical_cols])\n",
        "# predict_data[numerical_cols]=scaler.transform(predict_data[numerical_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADWOH3xnnMGI",
        "outputId": "5bedd824-0f4f-4e1c-c467-22035d6af0d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brand : [0.25 1.   0.5  0.   0.75]\n",
            "Material : [0.33333333 0.         0.66666667 1.        ]\n",
            "Size : [0.5 0.  1. ]\n",
            "Compartments : [0.66666667 1.         0.11111111 0.77777778 0.         0.44444444\n",
            " 0.22222222 0.55555556 0.33333333 0.88888889]\n",
            "Laptop Compartment : [1. 0.]\n",
            "Waterproof : [0. 1.]\n",
            "Style : [1.  0.5 0. ]\n",
            "Color : [0.  0.6 1.  0.2 0.4 0.8]\n",
            "Weight Capacity (kg) : [0.26446891 0.88314146 0.4657504  ... 0.18195835 0.311632   0.46566955]\n"
          ]
        }
      ],
      "source": [
        "for i in x.columns:\n",
        "  print(f\"{i} : {x[i].unique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7_5ltTsnMGJ"
      },
      "outputs": [],
      "source": [
        "x_torch=torch.tensor(x.values,dtype=torch.float32)\n",
        "y_torch=torch.tensor(y.values,dtype=torch.float32)\n",
        "# predict_data_torch=torch.tensor(predict_data.values,dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLjSFZ3anMGJ",
        "outputId": "bd053a43-f741-480a-f784-85151196dca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3288503, 9])\n",
            "torch.Size([3288503])\n"
          ]
        }
      ],
      "source": [
        "print(x_torch.shape)\n",
        "print(y_torch.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reTOYjkvnMGK"
      },
      "outputs": [],
      "source": [
        "batch_size = 512  # Reduce further if memory issues persist\n",
        "train_dataset = TensorDataset(x_torch, y_torch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJTMuxh7nMGK"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NIM-glm7nMGL"
      },
      "outputs": [],
      "source": [
        "class PricePredictionNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(PricePredictionNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 18)\n",
        "        self.fc2 = nn.Linear(18, 12)\n",
        "        self.fc3 = nn.Linear(12, 12)\n",
        "        self.fc4 = nn.Linear(12, 1)# Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x=F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)  # No activation (regression task)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHpyrGhpnMGL"
      },
      "outputs": [],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_torch, y_torch, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJWQ2BzRnMGL"
      },
      "outputs": [],
      "source": [
        "batch_size = 512  # Reduce further if memory issues persist\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "val_dataset = TensorDataset(x_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjJS7DMInMGM"
      },
      "outputs": [],
      "source": [
        "class PricePredictionNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(PricePredictionNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 1) # Output layer\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)  # Dropout layer with probability 0.2\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)  # Apply dropout\n",
        "        x = F.relu(self.fc3(x)) # No activation (Regression task)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9saaarcbnMGM"
      },
      "outputs": [],
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def forward(self, predictions, targets):\n",
        "        mse = F.mse_loss(predictions, targets)\n",
        "        return torch.sqrt(mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO_3srQRnMGN",
        "outputId": "1659871f-c08e-459e-d4b5-6656f3f1f42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "Loss of last batch: 39.6585, at Epoch 0\n",
            "Loss of last batch: 37.7339, at Epoch 100\n",
            "Loss of last batch: 38.6018, at Epoch 200\n",
            "Loss of last batch: 39.1955, at Epoch 300\n",
            "Loss of last batch: 37.7447, at Epoch 400\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Initialize model\n",
        "input_size = x_torch.shape[1]\n",
        "model = PricePredictionNN(input_size).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = RMSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.002, weight_decay=1e-4)  # L2 regularization (weight decay)\n",
        "\n",
        "# Training loop with Early Stopping\n",
        "epochs = 500\n",
        "# patience = 50  # Stop if no improvement for 50 epochs\n",
        "# best_val_loss = float('inf')\n",
        "# epochs_no_improve = 0\n",
        "\n",
        "# Lists to store loss values for plotting\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Training Phase\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)  # Move to GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch_X)\n",
        "        loss = criterion(predictions.reshape(-1), batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)  # Compute average training loss\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for val_X, val_y in val_loader:\n",
        "            val_X, val_y = val_X.to(device), val_y.to(device)\n",
        "            val_predictions = model(val_X)\n",
        "            val_loss += criterion(val_predictions.reshape(-1), val_y).item()\n",
        "\n",
        "    val_loss /= len(val_loader)  # Compute average validation loss\n",
        "\n",
        "    # Store losses for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Print loss every 100 epochs tjis is loss of last batch at every 100th epoch\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Loss of last batch: {loss.item():.4f}, at Epoch {epoch}\")\n",
        "\n",
        "    # Early Stopping Check\n",
        "    # if val_loss < best_val_loss:\n",
        "    #     best_val_loss = val_loss\n",
        "    #     epochs_no_improve = 0\n",
        "    # else:\n",
        "    #     epochs_no_improve += 1\n",
        "\n",
        "    # if epochs_no_improve >= patience:\n",
        "    #     print(f\"Early stopping at epoch {epoch}. Best validation loss: {best_val_loss:.4f}\")\n",
        "        # break  # Stop training\n",
        "\n",
        "print(\"Training complete!\")\n",
        "print('train losses : ',train_losses)\n",
        "print('validation losses : ',val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zc1RNL4SnMGO"
      },
      "outputs": [],
      "source": [
        "# Plot Training & Validation Loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label=\"Training Loss\")\n",
        "plt.plot(val_losses, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss (RMSE)\")\n",
        "plt.title(\"Training & Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1ABmFsQnMGP"
      },
      "source": [
        "**Submission**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_dGAt8gnMGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa497348-e0da-44d9-e5a7-3bc2fa7672a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[36.56239187  0.43760813]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[2, 4], [1, 4]])\n",
        "singular_values = np.linalg.svd(np.dot(A,A.T), compute_uv=False)\n",
        "print(singular_values)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[2, 4], [1, 4]])\n",
        "singular_values = np.linalg.svd(A, compute_uv=False)\n",
        "print(singular_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-vPeZAgyzAH",
        "outputId": "8d3e2943-5230-4965-f600-2527e7af0620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.04668437 0.66151956]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 10995111,
          "sourceId": 90274,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30886,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}